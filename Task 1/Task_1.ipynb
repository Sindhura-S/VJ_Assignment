{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d441b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\VJ_Assignment\\coco_sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!mkdir -p coco_sample\n",
    "%cd coco_sample\n",
    "\n",
    "# Download 2017 training images (~500MB for all, but we’ll filter to 100)\n",
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!unzip -q train2017.zip\n",
    "\n",
    "# Download full annotations\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip -q annotations_trainval2017.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788eccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import move\n",
    "from glob import glob\n",
    "\n",
    "os.makedirs(\"mini_train2017\", exist_ok=True)\n",
    "image_list = sorted(glob(\"train2017/*.jpg\"))[:100]  # Take first 100 images\n",
    "\n",
    "for img_path in image_list:\n",
    "    move(img_path, \"mini_train2017/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59bd593",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotations/instances_train2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load full annotations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mannotations/instances_train2017.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     data = json.load(f)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Keep only images we selected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'annotations/instances_train2017.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load full annotations\n",
    "with open(\"annotations/instances_train2017.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Keep only images we selected\n",
    "mini_image_ids = set([int(os.path.basename(f).split('.')[0]) for f in image_list])\n",
    "mini_images = [img for img in data['images'] if img['id'] in mini_image_ids]\n",
    "mini_annotations = [ann for ann in data['annotations'] if ann['image_id'] in mini_image_ids]\n",
    "mini_categories = data['categories']  # keep all classes\n",
    "\n",
    "# Save new mini annotation file\n",
    "mini_data = {\n",
    "    \"images\": mini_images,\n",
    "    \"annotations\": mini_annotations,\n",
    "    \"categories\": mini_categories\n",
    "}\n",
    "\n",
    "with open(\"instances_mini_train2017.json\", \"w\") as f:\n",
    "    json.dump(mini_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_coco_annotations(annotation_file):\n",
    "    \"\"\"\n",
    "    Loads COCO-style annotations from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        annotation_file (str): Path to the COCO annotations file (.json).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing images, annotations, and categories.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(annotation_file):\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {annotation_file}\")\n",
    "\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Basic sanity checks for key fields\n",
    "    required_keys = [\"images\", \"annotations\", \"categories\"]\n",
    "    for key in required_keys:\n",
    "        if key not in coco_data:\n",
    "            raise ValueError(f\"Missing key '{key}' in COCO annotations.\")\n",
    "\n",
    "    return coco_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask_from_annotations(image_info, annotations, category_map, image_size):\n",
    "    import numpy as np\n",
    "    from pycocotools import mask as maskUtils\n",
    "    import logging\n",
    "\n",
    "    height, width = image_size\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for ann in annotations:\n",
    "        try:\n",
    "            category_id = ann[\"category_id\"]\n",
    "            class_index = category_map.get(category_id, 0)\n",
    "\n",
    "            # Handle RLE and polygon differently\n",
    "            if ann.get(\"iscrowd\", 0):\n",
    "                rle = ann[\"segmentation\"]\n",
    "                if isinstance(rle, list):  # sometimes malformed\n",
    "                    continue\n",
    "                binary_mask = maskUtils.decode(rle)\n",
    "            else:\n",
    "                rle = maskUtils.frPyObjects(ann[\"segmentation\"], height, width)\n",
    "                binary_mask = maskUtils.decode(rle)\n",
    "\n",
    "            # Handle masks with multiple instances (H, W, N)\n",
    "            if binary_mask.ndim == 3:\n",
    "                binary_mask = np.max(binary_mask, axis=2)\n",
    "\n",
    "            binary_mask = binary_mask.squeeze()\n",
    "\n",
    "            # Apply class index where mask == 1\n",
    "            mask = np.where(binary_mask == 1, class_index, mask)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Annotation skipped due to error: {e}\")\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ff49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def save_mask_and_image(mask, image_path, output_dir, file_name):\n",
    "    \"\"\"\n",
    "    Saves the generated mask as a PNG and copies the original image to the output folder.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): Segmentation mask with class indices.\n",
    "        image_path (str): Path to the original image file.\n",
    "        output_dir (str): Root output directory (e.g., \"./processed_dataset/\").\n",
    "        file_name (str): Image file name (e.g., \"000000000009.jpg\").\n",
    "\n",
    "    Saves:\n",
    "        ./processed_dataset/images/file_name\n",
    "        ./processed_dataset/masks/file_name (as .png)\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'masks'), exist_ok=True)\n",
    "\n",
    "    # Save original image\n",
    "    image_dest = os.path.join(output_dir, 'images', file_name)\n",
    "    if not os.path.exists(image_dest):\n",
    "        os.system(f'cp \"{image_path}\" \"{image_dest}\"')\n",
    "\n",
    "    # Save mask as PNG with same name\n",
    "    mask_img = Image.fromarray(mask.astype(np.uint8))\n",
    "    mask_dest = os.path.join(output_dir, 'masks', file_name.replace('.jpg', '.png'))\n",
    "    mask_img.save(mask_dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473df01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"COCO to Segmentation Mask Converter\")\n",
    "    parser.add_argument('--images_dir', required=True, help='Path to folder containing images')\n",
    "    parser.add_argument('--annotation_file', required=True, help='Path to COCO-style annotation .json file')\n",
    "    parser.add_argument('--output_dir', default='./processed_dataset', help='Path to save processed masks and images')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    # Load annotation file\n",
    "    coco_data = load_coco_annotations(args.annotation_file)\n",
    "    image_id_to_anns = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id_to_anns.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "    # Build category_id → class_index map\n",
    "    category_map = {cat['id']: idx + 1 for idx, cat in enumerate(coco_data['categories'])}  # 0 is background\n",
    "\n",
    "    for image_info in tqdm(coco_data['images'], desc=\"Processing images\"):\n",
    "        try:\n",
    "            image_id = image_info['id']\n",
    "            file_name = image_info['file_name']\n",
    "            image_path = os.path.join(args.images_dir, file_name)\n",
    "            height, width = image_info['height'], image_info['width']\n",
    "            anns = image_id_to_anns.get(image_id, [])\n",
    "\n",
    "            mask = generate_mask_from_annotations(image_info, anns, category_map, (height, width))\n",
    "            save_mask_and_image(mask, image_path, args.output_dir, file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to process {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(images_dir, annotation_file, output_dir):\n",
    "    \"\"\"\n",
    "    Runs the full segmentation preprocessing pipeline for a COCO-style dataset in Colab.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Directory containing input images.\n",
    "        annotation_file (str): Path to COCO-style annotation file (.json).\n",
    "        output_dir (str): Output directory for processed masks and copied images.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    coco_data = load_coco_annotations(annotation_file)\n",
    "\n",
    "    image_id_to_anns = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id_to_anns.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "    category_map = {cat['id']: idx + 1 for idx, cat in enumerate(coco_data['categories'])}\n",
    "\n",
    "    for image_info in tqdm(coco_data['images'], desc=\"Processing images\"):\n",
    "        try:\n",
    "            image_id = image_info['id']\n",
    "            file_name = image_info['file_name']\n",
    "            image_path = os.path.join(images_dir, file_name)\n",
    "            height, width = image_info['height'], image_info['width']\n",
    "            anns = image_id_to_anns.get(image_id, [])\n",
    "\n",
    "            mask = generate_mask_from_annotations(image_info, anns, category_map, (height, width))\n",
    "            save_mask_and_image(mask, image_path, output_dir, file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to process {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(\n",
    "    images_dir=\"/content/coco_sample/mini_train2017\",\n",
    "    annotation_file=\"/content/coco_sample/instances_mini_train2017.json\",\n",
    "    output_dir=\"/content/processed_dataset\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ab41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract category_map globally from your existing annotation file (same as Task 1)\n",
    "import json\n",
    "\n",
    "with open(\"/content/coco_sample/instances_mini_train2017.json\", \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "category_map = {cat['id']: idx + 1 for idx, cat in enumerate(coco_data['categories'])}\n",
    "print(f\"Number of classes (including background): {len(category_map) + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef9e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(\"/content/processed_dataset/images/000000000009.jpg\")\n",
    "mask = Image.open(\"/content/processed_dataset/masks/000000000009.png\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[1].imshow(mask, cmap='gray')\n",
    "axs[1].set_title(\"Segmentation Mask\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
